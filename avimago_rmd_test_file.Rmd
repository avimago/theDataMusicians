---
title: "Factors Impacting Employee Attrition"
author: "H W Chen, A Mago, W Marshall, H Song, S S Swamy, X Zhong"
date: "October 13, 2017"
output:
  html_document:
    number_sections: yes
    toc: yes
  pdf_document:
    number_sections: yes
    toc: yes
csl: harvard-imperial-college-london.csl
bibliography: bibliography_MathStats.bib
---

\pagebreak

```{r echo=FALSE, message=FALSE, warning=FALSE}
# if package is not installed, use install.packages("library_name") to install
library(dplyr)
library(ggplot2)
library(gridExtra)
library(corrgram)
library(knitr)
library(visreg)
library(stargazer)
library(oddsratio)
library(formattable)
library(scales)
library(kableExtra)
library(caret)
```

```{r, echo = FALSE}
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```


# Introduction

## The Attrition Problem 
The competition for employers to acquire and retain talent is just as furious as that for candidates to get into an organization. Moreover, employers have to bare the different costs associated with employee attrition. Example cost implications are the costs required to recruit a new person to cover the role, the man-hours, or wage, lost due to lower efficiency of new recruits, and training costs. An article on the Robert Half website estimated that it takes on average 28 days to recruit for an open position @robertHalf. In some cases, it might even take months before the human resources (HR) team can hire someone suitable to fill the gap. According to Schawbel, “The biggest priority, and concern, for business leaders in 2017 will be retaining employees in a competitive talent marketplace.” @fortuneEmployersWorry 

Retention is a growing concern for organizations in both the private and public sectors: employee turnover rates have been on the increase in Europe and the US for some time. Whilst it may be of benefit to the employees, it undoubtedly levies considerable costs on the employers. Research from Bersin Deloitte reported that the talent acquisition spending of US companies increased by 7% on average from 2013 to $4000 per hire in 2014 @Cision. As recruiters struggle, many reach out to consultancies for help. Consultancy.uk revealed that the HR consulting market grew by 4.8% from 2014 to 2015. It can be seen that increasing retention is important @ConsultancyUK. Hence, we are exploring an HR data set to analyze variables that can affect attrition.
 
In order to improve retention in a company it would be of great benefit to know those factors that influence an employee's decision to leave, and to understand the relationships between these factors. Obvious examples would be the financial reward per unit time contributed, benefits and working hours. Indeed.com, an American job search engine, published a report on job tenure which showed that career advancement and compensation are by far the leading reasons for changing companies, followed by work environment and work life balance @indeedJobTenure. Depending on what the job entails and the individual, other influencers could include: working environment, distance from home, the amount of travelling required, relationship with colleagues, sense of achievement, autonomy, personal development. 

![Attrition Factors from Indeed](indeedShowMeTheMoney.png) 

We would like to test whether the above is true from a dataset obtained from Kaggle, a data-related website. More broadly, we would like to advise companies on methods to retain their valuable employees. To do this, there are two problems to solve. Firstly, this report identifies influencers that contribute most to an employee taking the decision to leave the company. This is followed by a regression model that predicts the impact of certain variables on the likelihood of an employee leaving. The model will highlight to the company who they risk losing. Then, based on our information, the employer can design bespoke schemes or programmes which aim to prevent the high risk employees from leaving. 

# Method

The analysis will start with plotting relationships between the different variables. By observation, a discrepancy between the distribution of employees who left and those who have not is an indication that the variable influences attrition. This analysis will then lead to a series of hypothesis tests, conducted to determine whether the relationship is statistically significant. Lastly, regression models can be compiled to predict attrition and to explore the influencer’s contribution to the likelihood of an employee leaving.

## About the Data Set- Descriptive Statistics

```{r echo=FALSE, message=FALSE, warning=FALSE}
IBM <- read.csv("WA_Fn-UseC_-HR-Employee-Attrition.csv")
colnames(IBM)[1] <- "Age"  # correct faulty column name of the first column

# columns such as employee number are not relevant or where all entries are the same, keep only relevant columns with varying inputs
IBM <- select(IBM, Age:EducationField, EnvironmentSatisfaction:NumCompaniesWorked, OverTime:RelationshipSatisfaction, StockOptionLevel:YearsWithCurrManager)
```

This is a cross-sectional dataset of survey answers and objective information regarding the employees of IBM. It has a total of 1470 observations (employees) across 35 variables (information about the employee). The variables can be broadly divided into three groups: personal information, job specific information, and subjective ratings. 

In our analysis, the columns EmployeeCount and EmployeeNumber are not useful, and the values in Over18 and StandardHour are the same for all employees (Yes and 80 respectively), so these four columns are filtered out to make our analysis more efficient.

```{r, echo=FALSE}
#Total Satisfaction (See commit SHA - f2c21d6c)
IBM <-  mutate(IBM, TotalSatisfaction=EnvironmentSatisfaction+JobSatisfaction+RelationshipSatisfaction+WorkLifeBalance)

#Converting variables into Factor Variables
IBM$Education<-ordered(IBM$Education,levels=c("1","2","3","4","5"))
IBM$JobSatisfaction<-ordered(IBM$JobSatisfaction,levels=c("1","2","3","4"))
IBM$JobLevel<-ordered(IBM$JobLevel,levels=c("1","2","3","4"))
IBM$JobInvolvement<-ordered(IBM$JobInvolvement,levels=c("1","2","3","4"))
IBM$StockOptionLevel<-ordered(IBM$StockOptionLevel,levels=c("0","1","2","3"))
IBM$RelationshipSatisfaction<-ordered(IBM$RelationshipSatisfaction,levels=c("1","2","3","4"))
IBM$WorkLifeBalance<-ordered(IBM$WorkLifeBalance,levels=c("1","2","3","4"))

```

The dataset has several ordered factor variables that are logged as integers. For example, the Education column uses integers between 1 to 5 to refer to the level of education of this employee. The numbers respectively means 'below college', 'college', 'bachelor', 'master' and 'doctor'. To catogerize the education level, the integers indicating the education level were changed into factors. The same approach was taken for similar variables including 'JobLevel', 'StockOptionLevel' and 'TrainingTimeLastYear'. 

**Variables related to employee personal information are shown in the following table:**

```{r echo=FALSE, message=FALSE, warning=FALSE}

personal <- data.frame(Variable=c("Age", "DistanceFromHome", "Education",
                                   "EducationField", "Gender", "MaritalStatus",
                                   "NumCompaniesWorked","TotalWorkingYears"),
                       Type=c("Integer","Integer","Factor","Factor","Factor","Factor","Integer","Integer"),
                       Description=c("The Employee's age", 
                                     "The distance from home to work", 
                                     "Level of education (1 'Below College', 2 'College', 3 'Bachelor', 4 'Master', 5 'Doctor')",
                                     "The subject of the employee's education (Human Resources, Life Sciences, Marketing, Medical, Other, Technical Degree)", 
                                     "Gender of this employee", "Marital status of this employee (Divorced, Married, Single)",
                                     "The number of companies this employee has worked in", "Total number of years this employee has worked since graduation"))

kable(personal, caption = "Personal Information", align='l')
```

**Variables relating to the employee's job at the company includes the following:** 

```{r echo=FALSE, message=FALSE, warning=FALSE}

jobinfo <- data.frame(Variable=c("Attrition","BusinessTravel","DailyRate","Department","HourlyRate","JobInvolvement",
                                 "JobLevel","JobRole", "MonthlyIncome", "MonthlyRate", "OverTime", "PercentSalaryHike",
                                 "PerformanceRating","StockOptionLevel", "TrainingTimesLastYear","YearsAtCompany",
                                 "YearsInCurrentRole", "YearsSinceLastPromotion","YearsWithCurrManager"),
                      Type=c("Factor","Factor","Integer","Factor","Integer","Factor","Factor","Factor","Integer","Integer",
                             "Factor","Integer","Factor","Factor","Factor","Integer","Integer","Integer","Integer"),
                      Description=c("If this employee left the company or not", "The frequency of business travel", "The daily rate of the employee", 
                                    "The department of this employee (Human Resource, Research & Development and Sales)","The hourly rate of the employee","1 'Low', 2 'Medium', 3 'High', 4 'Very High'","The level of this employee's job","The position of this employee (Sales Executive, Research Scientist, Laboratory Technician, Manufacturing Director, Healthcare Representative, Manager, (Other))", "The salary of this employee","The monthly rate of the employee", "If this employee works over time (Yes, No)", "The percentage of salary hike", "1 'Low', 2 'Good', 3 'Excellent', 4 'Outstanding'", "The amount of stock this employee possesses", "The length of training the employee took last year", "The number of years this employee has been in the company", "The number of years this employee has been in this position","The number of years since last promotion", "The number of years this employee has been with current manager"))

kable(jobinfo, caption = "Job Information", align='l')
```

**Lastly, subjective ratings that are possibly obtained from a survey are captured by the following variables:** 

```{r echo=FALSE, message=FALSE, warning=FALSE}
totals <- data.frame(Variable=c("EnvironmentSatisfaction","JobSatisfaction","RelationshipSatisfaction","WorkLifeBalance"),
                     Type=c("Factor","Factor","Factor","Factor"),
                     Description=c("Satisfaction derived from the environment (1 'Low', 2 'Medium', 3 'High', 4 'Very High')",
                                   "Satisfaction derived from the job (1 'Low', 2 'Medium', 3 'High', 4 'Very High')",
                                   "Satisfaction derived from relationships (1 'Low', 2 'Medium', 3 'High', 4 'Very High')",
                                   "The work life balance rate (1 'Bad', 2 'Good', 3 'Better', 4 'Best')"))

kable(totals, caption = "Satisfaction to the Job in Total", align='l')
```

**The gender distribution of the 1470 employees is such that 2/3 of these employees are male, as per the pie chart below:**

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggplot(IBM, aes(x = factor(""), fill = Gender))+geom_bar()+coord_polar(theta = "y")+labs(title = "Gender Distribution")+scale_x_discrete("")+theme_minimal()
```

The dataset includes information about employees from 3 different departments in 7 different roles. The composition is such: ~67% of the recorded employees are from the Research & Development department, ~4% employees recorded were from the Human Resources department, and employees from Sales took up the remaining part. 

```{r echo=FALSE}
ggplot(IBM,aes(JobRole, fill=Department))+geom_bar(position="dodge")+theme(axis.text = element_text(angle = 65,hjust = 1))
```

The graph demonstrates that managers act as somewhat of an outlier in this data set. Firstly, there are a very small number of managers and the manager role is the only cross-department role. Second, the attrition rate between managers and non-managers differed significantly: only 4.9% of managers left the company, compared 16.1% of all employees. To reduce noise and avoid the issue of multicollinearity, data related to the manager role is filtered out during analysis. 

A report conducted by indeed.com shows that compensation is critical in the decision of an employee to either leave or stay at a company. Two graphs are ploted below to show the distribution of monthly income. Most employees recieved a salary between £2500 and £7500. Apart from managers, the role of Research Director has the highest monthly income with an average at 16034. The roles of Healthcare Representative, Manufacturing Director and Sales Executive earned around half as much, at £7528.76, £7295.14 and £6924.28 on average, respectively. Employees in other roles were compensated less than this.

```{r echo=FALSE}
sal1<-ggplot(IBM,aes(MonthlyIncome))+geom_density()
#ggplot(IBM,aes("" ,MonthlyIncome))+geom_boxplot()
sal2 <- ggplot(IBM,aes(JobRole,MonthlyIncome))+geom_boxplot()+theme(axis.text = element_text(angle = 65,hjust =1))
grid.arrange(sal1,sal2, ncol=2)
#mean(IBM[IBM[,"JobRole"]=="Research Director","MonthlyIncome"])
#mean(IBM[IBM[,"JobRole"]=="Healthcare Representative","MonthlyIncome"])
#mean(IBM[IBM[,"JobRole"]=="Sales Executive","MonthlyIncome"])
```

## Strengths and Limitations
In the cleaning phase of the project, the dataset used provided clear benefits and limitations. The first great benefit was cleanliness: the data was very clean, there were no missing values or erroneous results. The second benefit was detail. The data set recorded information on 35 variables captured through an internal survey, such abundance gives us a valuable insight into the treatment of employees from different parts of the company. The inclusion of subjective ordered factorial variables facilitate the capture of some of the emotional and personal feelings towards the workplace. Packaged together, this data allows the analyst to take a holistic approach towards the analysis, that is, it could be pivotal for the firm to understand the factors which affect attrition that they can control, and those they cannot.

There is no light without dark, and there were several limitations to the dataset. The first clear limitation was the small sample size, 1470 is a small number of observations to generate any widely conclusive evidence about a population. Secondly, 81% of the respondents in the dataset had not left the company and thus, due to imbalanced proportions between the classes, it is difficult to find out who leaves and why. A third limitation was that a few of the variable classes were not fully defined, namely MonthlyRate, HourlyRate and DailyRate. Assumptions were made as to the true meaning of these. Although already outlined as a positive, another limitation was subjectivity. There were many subjective variables and it is impossible to know how accurate the information is or how accurately the respondents acted when filling out the survey. In an extreme case, imagine an employee who has just been fired. Their response at that moment will not reflect accurately how they felt on a day-to-day basis within the organisation.

# Analysis

```{r, echo=FALSE}
IBM <- filter(IBM, JobRole!="Manager")
```

## Distribution With Respect to Attrition
In this section, the distribution of the different variables are plotted and observed. The aim is to discover discrepancies between the employees that left the company and those who didn't. Although the graphs will not provide a proof of causalty, it will give an indication of whether a certain variable is related to attrition. 

After plotting and observing all the variables, the graphs that showed the most interesting trends are presented below. 

```{r distributionPlots, echo=FALSE,message=FALSE, align="center"}
p_Dist<-ggplot(IBM,aes(x=DistanceFromHome,fill=Attrition))+geom_histogram(position="fill",binwidth=3)
p_jsat<-ggplot(IBM,aes(x=JobSatisfaction,fill=Attrition))+geom_bar(position="fill")
p_role<-ggplot(IBM,aes(x=JobRole,fill=Attrition))+geom_bar(position="fill")+theme(axis.text = element_text(angle = 45,hjust = 1))
p_IncoRole<-ggplot(IBM, aes(x=JobRole, y=MonthlyIncome))+geom_boxplot()+theme(axis.text = element_text(angle = 45,hjust = 1))
p_income<-ggplot(IBM,aes(x=MonthlyIncome,fill=Attrition))+geom_histogram(position="fill", binwidth=2500)
p_years<-ggplot(IBM,aes(x=YearsAtCompany,fill=Attrition))+geom_density(adjust=1.5, position="fill")
p_biztrav<-ggplot(IBM,aes(x=BusinessTravel,fill=Attrition))+geom_bar(position="fill")+theme(axis.text = element_text(angle = 45,hjust = 1))
p_wlbalance<-ggplot(IBM,aes(x=WorkLifeBalance,fill=Attrition))+geom_bar(position="fill")

# create a grid to display graphs in a more compact form 
#grid.arrange(p_income, p_years,  ncol=2, widths=c(3,3))
```

**Effect of income**

According to the report on work force movement published by indeed.com @indeedJobTenure, job compensation is the second most popular reason for moving from a company. The above graph on attrition rate with regards to monthly income shows an agreement with the findings of indeed.com. Leavers are concentrated in the low-income range. Interestingly, a sizeable attrition rate is also observed in the upper quartile of monthly income. If this is still the case when other influential variables are held constant, IBM may need to investigate further. Possible reasons can be that these talents are too popular so other companies are willing to offer more to get them or that they are hired on a temporary contract basis.

```{r,echo=FALSE}
p_income
```


**Effect of years spent at the company**

An article on TLNT claimed that employers lose a third of their new hires within the first six months @talent. The graph yielded from this dataset agrees with this to some extent. The percentage of attrition decreases during the first 20 years. However, there are spikes in attrition for people who have been in the company for around 32 and 40 years, to around 90 percent. This could be caused by people retiring or stepping back to do a less demanding role elsewhere. To sum up, People are more likely to leave the company during the first few years or after staying for more than 30 years.

```{r echo=FALSE}
p_years
```


**Percentage who leave with respect to job role**

In general, some job roles are more attractive to the general public than others. Hence, the attrition distibution across job roles is plotted. The bar chart demonstrates that sales representatives have the highest attrition rate followed by laboratory technicians and Human Resources. The high attrition rate for sales representatives, laboratory technicians and HR can be related to the low wage of the roles shown above.  

It is worth noting that although sales executive has relatively high salary, their attrition rate is also high. Further studies can involve understanding why this group of employees is different to the norm. 


```{r,echo=FALSE}
p_role
# create a grid to display graphs in a more compact form 
#grid.arrange(p_Dist,p_jsat, p_biztrav,p_wlbalance, ncol=2)
```

**Effect of distance from home**

The graph shows that in general, employees are more likely to leave the company as distance from home increases from 0 to 25 miles. However, when the working distance is larger than 25 miles, the proportion of employees who leave the company decreases. This could be due to the fact that there is only a few employees that live more than 25 miles away from home. In other words, if a job office is too far away, more people might not even join the company to begin with.

```{r,echo=FALSE}
p_Dist
```

**Effect of job satisfaction**

Next, Job Satisfaction was investigated to gauge its influence on an IBM employee's decision on whether to stay or not. The above graph displays a negative relationship: as job satisfaction increases from 1 to 4, the percentage of attrition decreases from 24% to 10%. This thereby indicates that methods tailored to the improvement of job satisfaction could help to prevent employees from leaving the company.

```{r,echo=FALSE}
p_jsat
```

**Effect of business travel **

In this bar chart, it can be seen that higher attrition rate is associated with frequent business travel. Only 8 percent of employees want to leave company if their role does not require travelling, whereas, attrition spikes to 25 percent when the job requires frequent travel.

```{r,echo=FALSE}
p_biztrav
```

**Effect of work life balance**

On the indeed.com report @indeedJobTenure work like balance is the fourth largest contributor to attrition. Plots generated by the IBM dataset show that around 30 percent of employees choose to leave the company if they had a really bad work life balance (rating of 1). However as the level increases to 2 and more, the attrition percentage does not change significantly. It can suggest that once a work life balance threshold is met, effect for improvement is not obvious. 

```{r,echo=FALSE}
p_wlbalance
```

**Graphical Analysis Summary**

Eight graphs were shown aiming to find some relationship between attrition and other factors captured by the company. From the graphical analysis, it was found that monthly income, job satisfaction, distance from home and frequency of business travel show a potential influence on retention. However, we can only see a general trend through graphical Analysis. In the following parts, we will continue exploring the relationship between attrition and potential influencers through correlation and hypothesis tests.

##Correlation
```{r,echo=FALSE}
Corrgram_dataset <-select(IBM,TotalSatisfaction,Age,DistanceFromHome,NumCompaniesWorked,TotalWorkingYears,DailyRate,HourlyRate,MonthlyIncome,MonthlyRate,PercentSalaryHike,YearsAtCompany,YearsInCurrentRole,YearsSinceLastPromotion,YearsWithCurrManager)

library(corrgram)
corrgram(Corrgram_dataset,main="Correlogram of IBM data set", labels = c("TS","Age","Distance","NCW","TWY","DR","HR","MI","MR","PSH","YAC","YICR","YSLP","YWCM") )

Corrgram_dataset_key<-data.frame("Key" = c("TS","Age","Distance","NCW","TWY","DR","HR","MI","MR","PSH","YAC","YICR","YSLP","YWCM") , "Description"=c("TotalSatisfaction","Age","DistanceFromHome","NumCompaniesWorked","TotalWorkingYears","DailyRate","HourlyRate","MonthlyIncome","MonthlyRate","PercentSalaryHike","YearsAtCompany","YearsInCurrentRole","YearsSinceLastPromotion","YearsWithCurrManager"))
knitr::kable(Corrgram_dataset_key, caption="Description of Correlogram variables", align='l')
```

From the correlogram shown above, it is evident that there are not a lot of variables which are highly correlated to each other. This is reassuring for the regression analysis as this helps to avoid multi-collinearity.  Having said that, it is also evident that years at company, years in current role, years with current manager and years since last promotion are highly correlated.

From observing graphs plotted in the previous section, it can be seen that the higher the monthly income the less likely employee is going to leave. However, at the high end of the income spectrum, there is an unusual increase in attrition rate compared to those in the medium income range. This can be due to a mismatch in work experience, measured in total working years, and income rather than simply the level of income. Therefore, correlation between monthly income and total working years is examined. 

```{r,echo=FALSE,message=FALSE}
cor_all<-cor.test(IBM[,"MonthlyIncome"],IBM[,"TotalWorkingYears"])

cor_left<-cor.test(IBM[IBM[,"Attrition"]=="Yes","MonthlyIncome"],IBM[IBM[,"Attrition"]=="Yes","TotalWorkingYears"])

cor_stay<-cor.test(IBM[IBM[,"Attrition"]=="No","MonthlyIncome"],IBM[IBM[,"Attrition"]=="No","TotalWorkingYears"])

```

```{r,echo=FALSE,message=FALSE}
Sample<-c("All","Left","Stayed")
Variable1<-c("MonthlyIncome",
           "MonthlyIncome",
           "MonthlyIncome")
Variable2<-c("TotalWorkingYears",
            "TotalWorkingYears",
            "TotalWorkingYears")
Correlation<-round(c(cor_all$estimate,cor_left$estimate,cor_stay$estimate),3)
P_value<-scientific(c(cor_all$p.value,cor_left$p.value,cor_stay$p.value),2)
a<-data.frame(Sample,Variable1,Variable2,Correlation,P_value)

knitr::kable(a, caption = "Correlation Test Result", align='l')
```

The above table shows correlation between monthly income and total working years done in three different settings, one with all samples, one with people who left the company and one with people who are still at the company. For all samples, the correlation is quite high at 0.77 which validates our assumption that people who have more work experience, regardless of relevance to current job, typically earns a higher monthly salary. 

Separating the sample into people who left and people who stayed, it was found that amongst employees who left the company, the correlation between their monthly income and their work experience is lower than the people who are still at the company. Althought the difference is not significant it suggests that experience and income mismatch may lead to attrition. 

## Chi-Square Test 

Through graphical observation, some variables that influence attrition have been identified. In this section, hypothesis test is applied to these variables to further investigate their relevance to attrition. A Pearson's chi-square test is chosen because it can be used to determine whether there is a significant difference between the expected frequencies and the observed frequencies in one or more categories.This is suitable for data obtained from survey which is answered in limited multiple choice form. 

```{r,echo=FALSE,message=FALSE}
t_JobSat<-chisq.test(IBM$JobSatisfaction,IBM$Attrition)
t_JobRole <- chisq.test(IBM$JobRole, IBM$Attrition)
t_BizTravel<-chisq.test(IBM$BusinessTravel, IBM$Attrition)
t_WorkLife<-chisq.test(IBM$WorkLifeBalance, IBM$Attrition)

Variable1<-c("Attrition","Attrition","Attrition","Attrition")
Variable2<-c("JobSatisfaction","JobRole","BusinessTravel","WorkLifeBalance")
Chisq_P_Value<-c(t_JobSat$p.value,t_JobRole$p.value,t_BizTravel$p.value,t_WorkLife$p.value)
b<-data.frame(Variable1,Variable2,Chisq_P_Value)

knitr::kable(b, caption="Chi-Square Test Result", align='l')

```

The Chi-square test clearly shows evidence that the distributions for those people who leave and those who do not is statistically different in terms of their job satisfaction, role, frequency of business travel and work life balance. We can see this from the extremely low p-values displayed on the output. These results clearly suggest that regression analysis can be used as a method to quantify the impact of these differences on the attrition rate. It was proposed that such analysis would aid the company in the reduction of it’s attrition rate by strategizing efficiently.

##Regression Analysis

This report is making use of the logit regression model in order to analyse the impact of several variables on an individual’s odds for leaving the company. This analysis is initiated by looking at two models: one for those factors the company can directly influence in order to decrease its attrition rate, the other outlaying those which are of a more personal nature and where the company has limited scope for interference. This is then followed by a model which only takes into consideration the performance indicators of an individual. These models allow the study to take into consideration the nature of different variables. Finally, a full model which has all the variables is presented. The full model adds to the robustness of the results which are presented beforehand as the result is mostly in agreement with the results of other models.

Since this study makes use of a logit model, the coefficient on an independent variable signifies the change in log odds of attrition caused because of that specific variable. These results were transformed to obtain the change in odds which are more intuitive as it will help this report to identify factors which makes it more likely for people to quit their job. In order to make the results even more intuitive the Average Partial Effect (APE) was calculated for the final model.



###Simple Logit regression plots


```{r, echo=FALSE}
#Dataset creation for plotting and regression analysis

predictdata<-IBM
predictdata$Attrition<-factor(predictdata$Attrition,levels=c("No","Yes"),labels = c(0,1))

# Predictdata_avi created to make sure that the comparision in reg model (out of control) the dropped out category is married!
predictdata_avi <- predictdata
predictdata_avi$MaritalStatus<-factor(predictdata_avi$MaritalStatus,levels=c("Married","Single","Divorced"),labels = c(0,1,2))
predictdata_avi$MaritalStatus<-factor(predictdata_avi$MaritalStatus,levels=c(0,1,2),labels = c("Married","Single","Divorced"))
```


Before conducting the analysis, plots of the predictions made by a single variable logit model were analysed to check if they are in line with the basic assumptions about the impact of certain variables on attrition. The results from these simple predictive plots will be used as a motivation to conduct the main regression analysis.



####Impact of monthly income on attrition

The graph below clearly shows how the probability of attrition decreases as monthly income offered by a job increases. This is in line with the expected relationship since monetary incentive is a key driver for most individuals. These estimates can be used to inform the incentive schemes which minimises the attrition rate. The simple logit model result also highlights that monthly income is significant. Although the robustness of this result is questionable, it still adds to the motivation for doing a more complex regression analysis.



```{r, echo=FALSE}
#Monthly Income vs Attrition

simple_model_plot_1<-glm(Attrition~MonthlyIncome,data = predictdata_avi, family= binomial)

xv <- seq(min(IBM$MonthlyIncome), max(IBM$MonthlyIncome),10)
yv <- predict(simple_model_plot_1,list(MonthlyIncome = xv), type = "response")

ggplot()+labs(x="Monthly Income", y="Probability of Attrition")+geom_smooth(aes(x=xv,y=yv),method='loess')
```

```{r, echo=FALSE,results="asis"}
#Sixth, regressing Monthly Income on Attrition.
att_3 <- glm(formula = Attrition ~ MonthlyIncome, data = IBM, family=binomial)
stargazer(att_3, title = "Impact of Monthly Income on Attrition", type = 'html')
```

####Impact of Distance From Home on attrition

This graph displays a positive relationship between the distance from home and the probability of attrition. This is again in line with the expected relationship since distance adds to the inconvenience an employee might experience while commuting. This information can be used to design the travel benefits which a company might offer an employee to reduce attrition. Furthermore, the impact of distance from home is also statistically significant.


```{r, echo=FALSE}
#Distance From Home vs Attrition

simple_model_plot_2<-glm(Attrition~DistanceFromHome,data = predictdata_avi, family= binomial)

xv1 <- seq(min(IBM$DistanceFromHome), max(IBM$DistanceFromHome),1)
yv1 <- predict(simple_model_plot_2,list(DistanceFromHome = xv1), type = "response")

ggplot()+geom_smooth(aes(x=xv1,y=yv1),method='loess')+labs(x="Distance From Home", y="Probability of Attrition")
```

```{r, echo=FALSE,results="asis"}
#Second, regressing Attrition on DistanceFromHome
att_2 <- glm(formula = Attrition ~ DistanceFromHome, data = IBM, family=binomial)
stargazer(att_2, title = "Impact of Distance from Home on Attrition", type = 'html')
```

####Impact of Total Satisfaction on attrition

As expected, we can clearly see that as total satisfaction increases the predicted probability of attrition decrease.

Since these graphs show that our model performs as expected and the results are significant we build four multi-variable logit models as discussed above.



```{r, echo=FALSE}
#Total Satisfaction From Home vs Attrition

simple_model_plot_3<-glm(Attrition~TotalSatisfaction,data = predictdata_avi, family= binomial)

xv2 <- seq(min(IBM$TotalSatisfaction), max(IBM$TotalSatisfaction),1)
yv2 <- predict(simple_model_plot_3,list(TotalSatisfaction = xv2), type = "response")

ggplot()+geom_smooth(aes(x=xv2,y=yv2),method='loess')+labs(x="Total Satisfaction", y="Probability of Attrition")
```

```{r, echo=FALSE,results="asis"}
#First, regressing Attrition on Total Satisfaction
att_1 <- glm(formula = Attrition ~ TotalSatisfaction, data = IBM, family=binomial)
stargazer(att_1, title = "Impact of Total Satisfaction on Attrition", type = 'html')
```

###Multi-varibale logit models

####Company Control Model 

We can clearly see from the result below that business travel and overtime has the highest impact on the odds of attrition. The result suggests that the odd of attrition for an employee increases by a factor of 4.6 if the employee travels frequently for business work (compared to employees who don’t travel). This can be vital for a company as the company might want to spend more resources on finding people with a passion for traveling since it can be a major factor causing the employee to leave. Further to this, people who work over time have odds which are 4.9 times higher than people who don’t work overtime. This result can be used by the company to make changes in the monetary incentive for people who work overtime.



```{r, echo=FALSE,results="asis"}
#Model with only variables that a company can control
company_control_model_v1<-glm(Attrition~BusinessTravel+DailyRate+Department+HourlyRate+MonthlyIncome+NumCompaniesWorked+OverTime+PercentSalaryHike+TrainingTimesLastYear+YearsInCurrentRole+YearsSinceLastPromotion+YearsWithCurrManager+TotalSatisfaction,data = predictdata_avi, family= binomial)
```

**Odds Ratio Summary**
```{r, echo=FALSE}
#Odds Ratio Calculation for the model with only variables that a company can control
reg_out_control <- or_glm(data = predictdata_avi, model = company_control_model_v1, incr = list(TotalSatisfaction = 1, NumCompaniesWorked = 1 , DailyRate = 10, HourlyRate = 100, MonthlyIncome = 1000, PercentSalaryHike = 1, TrainingTimesLastYear = 1, YearsInCurrentRole = 1,YearsWithCurrManager=1,YearsSinceLastPromotion=1, CI = 0.95))

formattable(reg_out_control)
```

```{r,results="asis", echo=FALSE, results="asis"}
stargazer(company_control_model_v1, title="Regression Results for Company Control Model",
align = TRUE, covariate.labels=c("Business travel - frequently", "Business travel - rarely",
"Daily rate", "Research and Development(Dpt.)", "Sales(Dpt.)", "Hourly rate", "Monthly Income", "Number of companies worked", "Overtime - YES", "Percent salary hike", "Training times last year", "Years in current role", "Years since last Promotion", "Years with current manager", "Total Satisfaction", "Constant"), no.space=TRUE, type = "html")
```


####Company Out of Control Model 

Although this model has variables that might not be under direct influence of the company but it is still useful for the purpose of this study as the company can try to resolve the issue by offering a compensating incentive. The result from this model clearly shows that Martial Status has a huge impact on the odds of quitting a job. We can see that compared to a married worker the odds of quitting for a single worker is 2.5 times higher. This result is also highly significant. It is also interesting to note that as total working years increases by 1 the odds for attrition decreases by 8 percent. Also, an increase of 1 unit of total satisfaction causes the odds for attrition to fall by 22%. This suggests that the company can focus its resources on singles, newcomers and people who have low total satisfaction score.



```{r, echo=FALSE,results="asis"}
#Model with only variables that a company can't control
out_of_control_v1<-glm(Attrition~+EducationField+Gender+MaritalStatus+DistanceFromHome+NumCompaniesWorked+TotalWorkingYears+TotalSatisfaction,data = predictdata_avi, family= binomial)
```

**Odds Ratio Summary**
```{r, echo=FALSE}
#Odds Ratio Calculation for the model with only variables that a company can't control
reg_out_out_of_control <- or_glm(data = predictdata_avi, model = out_of_control_v1, incr = list(TotalSatisfaction = 1, NumCompaniesWorked = 1 , TotalWorkingYears = 1, MartialStatus = 1, DistanceFromHome = 10, CI = 0.95))

formattable(reg_out_out_of_control)
```


```{r, echo=FALSE, results="asis"}
stargazer(out_of_control_v1, title="Regression Results for Company Out of Control Model",
align = TRUE, covariate.labels=c("Education Field - Life Sciences", "Education Field - Marketing",
"Education Field - Medical", "Education Field - Other", "Education Field - Technical", "Male", "Single", "Divorced", "Distance from home", "Number of Companies Worked", "Total Working Years", "Total Satisfaction", "Constant"), omit.stat=c("LL","ser","f"), no.space=TRUE, type = "html")
```


####Performance Indicator Model 

The result of this model is similar to the two models presented above and thus adds to the robustness of the preceding models since the estimates on variables are not highly sensitive to specific variables in the model.


```{r, echo=FALSE,results="asis"}
#Model with only performance variables
model_reg_performance<-glm(Attrition~OverTime+PercentSalaryHike+TrainingTimesLastYear+YearsAtCompany+YearsInCurrentRole+YearsSinceLastPromotion+YearsWithCurrManager+TotalSatisfaction+BusinessTravel,data = predictdata_avi, family= binomial)

```


**Odds Ratio Summary**
```{r, echo=FALSE,results="asis"}
#Odds Ratio Calculation for model with only performance variables
reg_out_model_reg_performance <- or_glm(data = predictdata_avi, model = model_reg_performance, incr = list(TotalSatisfaction = 1 ,PercentSalaryHike = 1,TrainingTimesLastYear=1, YearsAtCompany = 1, YearsInCurrentRole = 1, YearsSinceLastPromotion = 1, YearsWithCurrManager = 1,  CI = 0.95))

formattable(reg_out_model_reg_performance)

stargazer(model_reg_performance, title="Regression Results for Performance Model",
align = TRUE, covariate.labels=c("Overtime - YES", "Percent salary hike",
"Training Times Last Year", "Years at Company", "Years in Current Role", "Years Since Last Promotion", "Years with Current Manager", "Total Satisfaction", "Business Travel - Frequently", "Business Travel - Rarely", "Constant"), omit.stat=c("LL","ser","f"), no.space=TRUE, type = "html")
```


####Full Model 

The full model includes all relevant variables that might have an impact on attrition. The variables that have the most positive impact on odds of attrition are Business Travel, Over Time, Marital Status. This finding is consistent with our results in the previous models. In terms of average partial effect (APE), an employee travelling frequently for business work has a probability of leaving which is 20% higher compared to an employee who does not travel. Also, working overtime increases the probability of attrition by 18 percent. Furthermore, compared to a married employee a single employee has a 12% higher probability of leaving the job.
 
The full model suggests that a one point increase in total satisfaction results in a 32% decrease in odds of attrition. In terms of APE, the impact of a single point increase in total satisfaction is a 4% reduction in probability of attrition. Another interesting observation is of training provided last year. The probability of attrition decreases by 2% as the training provided increases by 1 unit.




```{r, echo=FALSE}
#Full Model 
full_model_reg_v1<-glm(Attrition~BusinessTravel+DailyRate+Department+DistanceFromHome+EducationField+HourlyRate+Gender+MaritalStatus+MonthlyIncome+NumCompaniesWorked+OverTime+PercentSalaryHike+TotalWorkingYears+TrainingTimesLastYear+YearsAtCompany+YearsInCurrentRole+YearsSinceLastPromotion+YearsWithCurrManager+TotalSatisfaction,data = predictdata_avi, family= binomial)
```

**Odds Ratio Summary**

```{r, echo=FALSE}
#Full Model Odds Ratio Calculation
reg_out_full_model <- or_glm(data = predictdata_avi, model = full_model_reg_v1, incr = list(TotalSatisfaction = 1, DistanceFromHome =5, NumCompaniesWorked = 1 , DailyRate = 10, HourlyRate = 100, MonthlyIncome = 1000, PercentSalaryHike = 1, TotalWorkingYears = 1, TrainingTimesLastYear = 1, YearsAtCompany = 1,YearsInCurrentRole = 1,YearsWithCurrManager=1,YearsSinceLastPromotion=1, Gender=1 , MartialStatus = 1, CI = 0.95))

formattable(reg_out_full_model)

```

**Average Partial Effect Summary**

```{r, echo=FALSE}
#Average Partial Effect Calculation for full model
APE_out <- round((mean(full_model_reg_v1$fitted.values * (1-full_model_reg_v1$fitted.values)))*full_model_reg_v1$coefficients,digits=2)

APE_out_data_frame <- as.data.frame(APE_out)

formattable(APE_out_data_frame)
```

#### Multi Variable Regression Model Summary
```{r, echo=FALSE, results="asis"}
stargazer(list(full_model_reg_v1,company_control_model_v1,out_of_control_v1,model_reg_performance), title="Regression Results Summary",align = TRUE, covariate.labels=c("Business Travel - Frequently", "Business Travel - Rarely","Daily Rate", "Research and Development(Dpt.)", "Sales(Dpt.)", "Distance From Home", "Education Field - Life Sciences", "Education Field - Marketing","Education Field - Medical", "Education Field - Other", "Education Field - Technical", "Hourly Rate", "Male", "Single", "Divorced", "Monthly Income", "Number of Companies Worked", "Overtime - YES", "Percent Salary Hike","Total Working Years","Training Times Last Year", "Years at Company", "Years in Current Role", "Years Since Last Promotion","Years with Current Manager","Total Satisfaction","Constant"), omit.stat=c("LL","ser","f"), type = "html", dep.var.caption = ('"(1)" Full (2) Control (3) Out (4) Perf'))

```


# Model Evaluation

Having modelled the data in order to find out which factors affect Attrition, it is important to evaluate the model in order to give credibility to its results. Here, in the case of a logistic regression, whilst the model with the lowest AIC was selected, it is still needed to come up with some sort of goodness of fit measure. Since the dependent variable in this case is Attrition, a factor variable, it makes sense to run a prediction on the model and gain the accuracy by tabulating the misclassifications of the predictions. In order to do this, the dataset needs to be split into a Training dataset, which the model will be run on, and a Test dataset, which will be used to compare how close the models predictions were. A split of 2:1 is chosen here, meaning that the test dataset will have a randomnly chosen 33.33% of the dataset.

```{r,echo=FALSE}
#Splitting the dataset and running models on the smaller samples
predictdata<-IBM
predictdata$Attrition <- factor(predictdata$Attrition, levels = c("No","Yes"),labels = c(0,1))
set.seed(58)
test_rows<-sample.int(nrow(predictdata),nrow(predictdata)/3)
test<-predictdata[test_rows,]
train<-predictdata[-test_rows,]

full_model_reg1<-glm(Attrition~BusinessTravel+DailyRate+Department+DistanceFromHome+Education+EducationField+Gender+HourlyRate+JobLevel+JobRole+MaritalStatus+MonthlyIncome+NumCompaniesWorked+OverTime+PercentSalaryHike+StockOptionLevel+TotalWorkingYears+TrainingTimesLastYear+YearsAtCompany+YearsInCurrentRole+YearsSinceLastPromotion+YearsWithCurrManager+TotalSatisfaction,data = train, family= binomial)
```

```{r,echo=FALSE,eval=FALSE}
#Making predictions on the training data
p<-predict(full_model_reg1,train,type="response")
pyes<-round(p)
head(pyes)
head(train[,2])
table(train[,2],pyes)
confusionMatrix(pyes,train[,2])
```

```{r,echo=FALSE}
df<-data.frame("Prediction" = c("No","Yes") , "No" = c(727,26), "Yes"=c(80,66))

kable(df,format = "html",caption = "Actual vs Predicted Attrition")%>%add_header_above(c(" ", "Actual" = 2))
```


From the confusion matrix, it is noticeable that the accuracy rate is 88%, implying that the model used is a good one. This high accuracy rate however is probably a bit optimistic as it uses the data that the model was trained on, and it is thus required to test this model on data which it hasn't seen before.

```{r,echo=FALSE,eval=FALSE}
#Making predictions on the test data
p1<-predict(full_model_reg1,test,type="response")
pyes1<-round(p1)
head(pyes1)
head(test[,2])
table(pyes1,test[,2])
confusionMatrix(pyes1,test[,2])
```

```{r,echo=FALSE}
df1<-data.frame("Prediction" = c("No","Yes") , "No" = c(342,17), "Yes"=c(54,30))
kable(df1,format = "html",caption = "Actual vs Predicted Attrition")%>%add_header_above(c(" ", "Actual" = 2))
```


Observing the confusion matrix, where the predictions are the rows and the actual class is the columns, it is visible that the accuracy is just the trace of the matrix divided by the total sum of each of the individual components. This makes sense as the main diagonal is essentially the cases where the model predicted the correct class. In this case, when we predict the data from the test dataset, we get an accuracy of 84%, implying that our model is good and has some predictive power. It is important to note however that the No Information Rate is 0.81 and the probability that the accuracy is better than the No Information Rate is 0.06, meaning that a model which just predicts all cases as the more popular case would be accurate 81% of the time and our current model isn't much better than this. This drawback becomes a bit more evident when it is observed that while the accuracy of predicting the 'positive' (No) class  is 0.95 (Sensitivity), the 'negative' (Yes) class is only predicted accurately 36% (Specificity) of the time, meaning that this model might not be very good to predict which employees leave. This being said, 64% (Negative Predictive Value) of all the cases that were predicted as 'negative' were actually 'negative', meaning that some predictive power can be inferred, given the imbalanced proportion between the two classes.


# Conclusion 
```{r}

```

To conclude, we provide a brief summary of our steps and the outcomes that were reached. First, we outlined the problem that needed to be solved, namely that the company wanted to understand the factors contributing significantly towards its attrition rate. It was claimed that a high attrition rate is costly for a company due to the higher training costs, recruitment initiatives and lost time. It was proposed that by understanding these factors a company would be able to use its resources more effectively when appealing to those who are most likely to leave for another employer. We then started our analysis by exploring the dataset and reducing it down to a form that would be more effective to work with- for example, we excluded all columns that contained data identical to every employee. On this topic, we also recognised that there could have been a multicollinearity issue had managers been included since it was observed that they at times spanned more than one department. On top of this, the attrition rate of managers ~5% and not really a problem to the employer. 

The graphical analysis shows potential links between income, frequency of business travel, office's distance from home and job satisfaction. Conducting chi-square tests on frequency of business travel, job satisfaction and worklife balance showed that they all influence attrition to a high confidence level. Although attrition rates are different for different job roles, it is very likely that it is due to the difference in wages of the roles. More interestingly, it was also discovered that a mismatch between years of experience and income can possibly lead to higher attrition rates. 

By conducting the regression analysis using logit, this study was able to quantify the impact of key drivers of attrition. These include the marital status of an employee, whether or not an employee works overtime and frequency of business travel. On the other hand, total satisfaction decreases the probability of attrition by 4%. The frequency of training also reduces the probability of attrition by 2% which also justifies why companies should focus on it. Evaluating the model, while the model predicted the test dataset accurately 84% of the time, due to the imbalanced proportion between the two classes, only 64% of all predictions of the minority class were accurate.

The results from the regression analysis suggests that the company should actually make changes in the type of people it hires who are involved in a lot of business travel. Further to this particular attention should be given to the overtime pay structure in order to reward their employees for the extra work.

\pagebreak

# Bibliography
